# Extended RealTabFormer and GReaT Models

This project extends the original RealTabFormer and GReaT models to support a broader range of decoder-only Large Language Models (LLMs), such as various GPT variants and Llama.

## 📖 Original Work & Credit

All credit for the original model development goes to the authors of the respective papers. This work builds upon their foundation, which was based on the GPT-2 architecture.
- **GReaT**: [https://arxiv.org/abs/2305.18511](https://arxiv.org/abs/2305.18511)
- **RealTabFormer**: [https://arxiv.org/abs/2305.18421](https://arxiv.org/abs/2305.18421)

**My Contribution**: I have modified both models to be compatible with other decoder-only LLMs beyond GPT-2.

## 🚀 Installation

The modified versions of GReaT and REaLTabFormer can be installed directly from TestPyPI.
Installation documents can be found on [README_GReaT.md](README_GReaT.md) and [README_REaLTabFormer.md](README_REaLTabFormer.md) files.

Note: If you encounter any installation issues, the package contents are also provided in this repository as a fallback (see the [generic-realtabformer/](generic_realtabformer-1.0.3136/) and [generic-be-great/](generic_be_great-0.0.8/) folders).

## 🧰 Usage

Instructions of how to use the GReaT and the REaLTabFormer models are explained on their README.md files (see [README_GReaT.md](README_GReaT.md) and [README_REaLTabFormer.md](README_REaLTabFormer.md) files)

## 📁 Project Structure
The repository is organized as follows:

``` bash
.
|── datasets/                 # Original datasets
|── execution/
|   - data_split/             # Datasets are split into train/test
|   - server_run_executions/  # Python codes for the Slurm (HPC)
|   - generated_datasets/     # Synthetic tabular data generated by the models. Due to the size restrictions, I uploaded them on my Google Drive
|   - results_analysis_code/  # Scripts to evaluate and calculate metrics on generated data
|   - final_results/          # Plots from the evaluation
```

## 🔄 Workflow
To reproduce the project, follow these steps in order:

1. Dataset Preparation: Start with the Dataset_split scripts to split your raw data into training and testing sets.

-> run jupyter notebook files in the [execution/data_split](execution/data_split) folder. 

2. Synthetic Data Generation: Execute the scripts in the folder of server_run_executions to generate synthetic data. The output will be saved in the Generated_Datasets folder.

Note: You will need to modify the paths and job parameters in these scripts to match your own directory structure in the Slurm if necessary or run the modified version on your laptop if your laptop has enough capacity.

-> run python files in the [execution/server_run_executions](execution/server_run_executions) folder.

-> synthetic datasets are supposed to be saved in the [execution/generated_datasets](execution/generated_datasets) folder. Due to the big size, I have uploaded them on [Google Drive](https://drive.google.com/file/d/1kW4V63Ef-VtnD7DZlgTNLjfcKoNRC2US/view?usp=sharing) publicly. If you download it, pls first unzip and replace the whole folder with the generated_datasets so that all the rest of the code will run smoothly.

3. Evaluation: Finally, run the scripts in Results_Codes to evaluate the quality of the generated synthetic data against the real test set, producing the final_results.

-> run jupyter notebook files in the [execution/results_analysis_code](execution/results_analysis_code) folder. 

-> the final result plots are supposed to be saved in the [final_results](final_results) folder. 

Detailed information of the research is explained on my [paper](master_thesis.pdf)


